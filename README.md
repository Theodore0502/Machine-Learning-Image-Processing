# ğŸŒ¾ Rice Leaf Health - Nháº­n Diá»‡n Bá»‡nh LÃºa Báº±ng Deep Learning

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Active-success.svg)

**Há»‡ thá»‘ng nháº­n diá»‡n bá»‡nh lÃºa tá»± Ä‘á»™ng sá»­ dá»¥ng CNN vÃ  Vision Transformer**

[TÃ­nh nÄƒng](#-tÃ­nh-nÄƒng-chÃ­nh) â€¢ [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t) â€¢ [Sá»­ dá»¥ng](#-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng) â€¢ [Káº¿t quáº£](#-káº¿tquáº£)

</div>

---

## ğŸ“‹ Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)
- [TÃ­nh nÄƒng chÃ­nh](#-tÃ­nh-nÄƒng-chÃ­nh)
- [Kiáº¿n trÃºc há»‡ thá»‘ng](#-kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [Táº­p dá»¯ liá»‡u](#-táº­p-dá»¯-liá»‡u)
- [Training](#-training)
- [HÆ°á»›ng dáº«n sá»­ dá»¥ng](#-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [ÄÃ¡nh giÃ¡](#-Ä‘Ã¡nh-giÃ¡-evaluation)
- [Trá»±c quan hÃ³a](#-trá»±c-quan-hÃ³a)
- [Cáº¥u trÃºc dá»± Ã¡n](#-cáº¥u-trÃºc-dá»±-Ã¡n)
- [Káº¿t quáº£](#-káº¿t-quáº£)
- [Troubleshooting](#-troubleshooting)
- [TÃ i liá»‡u tham kháº£o](#-tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ¯ Giá»›i thiá»‡u

**Rice Leaf Health** lÃ  dá»± Ã¡n nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn há»‡ thá»‘ng nháº­n diá»‡n bá»‡nh lÃºa tá»± Ä‘á»™ng sá»­ dá»¥ng Deep Learning, Ä‘Æ°á»£c xÃ¢y dá»±ng trong 2 tuáº§n cho mÃ´n **MÃ¡y há»c nÃ¢ng cao**.

### Má»¥c tiÃªu

- **Pháº§n A (MÃ´n MÃ¡y há»c nÃ¢ng cao)**: Classification sá»­ dá»¥ng CNN vÃ  ViT, kÃ¨m theo GradCAM/SAM Ä‘á»ƒ giáº£i thÃ­ch, export ONNX
- **Pháº§n B (MÃ´n khÃ¡c)**: Segmentation vá»›i SegFormer-B0, tÃ­nh % diá»‡n tÃ­ch bá»‹ bá»‡nh, dashboard Streamlit

### Äáº·c Ä‘iá»ƒm ná»•i báº­t

âœ… **Dual Model Support**: Há»— trá»£ cáº£ CNN (nhanh) vÃ  ViT (chÃ­nh xÃ¡c), dá»… dÃ ng chuyá»ƒn Ä‘á»•i  
âœ… **Production Ready**: Export ONNX, tá»‘c Ä‘á»™ < 80ms/áº£nh trÃªn CPU  
âœ… **Explainable AI**: GradCAM visualization Ä‘á»ƒ hiá»ƒu model Ä‘ang "nhÃ¬n" vÃ o Ä‘Ã¢u  
âœ… **Easy to Use**: Interface Ä‘Æ¡n giáº£n, phÃ¹ há»£p demo vÃ  bÃ¡o cÃ¡o  
âœ… **Academic Compliant**: ÄÃ¡p á»©ng yÃªu cáº§u mÃ´n há»c vá»›i F1 macro â‰¥ 0.80

---

## â­ TÃ­nh nÄƒng chÃ­nh

### 1. **Dual Model Architecture**

| Äáº·c Ä‘iá»ƒm | CNN (SmallCNN) | ViT (Small) |
|----------|----------------|-------------|
| **KÃ­ch thÆ°á»›c** | ~1.5 MB | ~87 MB |
| **Tá»‘c Ä‘á»™** | ~10-20 ms/áº£nh | ~50-100 ms/áº£nh |
| **Äá»™ chÃ­nh xÃ¡c** | F1 â‰ˆ 0.82-0.85 | F1 â‰ˆ 0.85-0.88 |
| **Use case** | Real-time, edge devices | Accuracy-critical |

### 2. **Flexible Prediction Interface**

```bash
# Dá»± Ä‘oÃ¡n vá»›i CNN (máº·c Ä‘á»‹nh - yÃªu cáº§u mÃ´n há»c)
python -m src.tools.predict --image temp/test1.jpg

# Dá»± Ä‘oÃ¡n vá»›i ViT (Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n)
python -m src.tools.predict --image temp/test1.jpg --model_type vit

# So sÃ¡nh cáº£ 2 model
python -m src.tools.predict --image temp/test1.jpg --model_type both
```

### 3. **Comprehensive Evaluation**

- Per-class metrics (Precision, Recall, F1)
- Confusion matrix
- Speed benchmarking
- Model comparison reports

### 4. **Explainability**

- GradCAM heatmaps
- Attention visualization (ViT)
- Top-k predictions vá»›i confidence scores

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

### Workflow Tá»•ng Quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input     â”‚ â†’ áº¢nh lÃ¡ lÃºa (224x224)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     CNN     â”‚    â”‚     ViT     â”‚   â”‚ Segmentation â”‚
â”‚ (SmallCNN)  â”‚    â”‚  (Small)    â”‚   â”‚ (SegFormer)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
                â–¼                            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Prediction  â”‚            â”‚ Disease Mask â”‚
         â”‚ + GradCAM   â”‚            â”‚ + % Area     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Architectures

#### CNN (SmallCNN)
```
Input (3Ã—224Ã—224)
  â†“
Conv2D(32) + BN + ReLU + MaxPool â†’ 32Ã—112Ã—112
Conv2D(64) + BN + ReLU + MaxPool â†’ 64Ã—56Ã—56
Conv2D(128) + BN + ReLU + MaxPool â†’ 128Ã—28Ã—28
Conv2D(256) + BN + ReLU + MaxPool â†’ 256Ã—14Ã—14
  â†“
Global Average Pooling â†’ 256
  â†“
Dropout(0.3) â†’ Linear(5 classes)
```

**Æ¯u Ä‘iá»ƒm**: Nháº¹, nhanh, dá»… deploy  
**NhÆ°á»£c Ä‘iá»ƒm**: KhÃ³ há»c global context

#### ViT (Vision Transformer Small)
```
Input (3Ã—224Ã—224)
  â†“
Patch Embedding (16Ã—16 patches) â†’ 196 patches
  â†“
Transformer Encoder (12 layers)
  - Multi-head Self-Attention
  - MLP + LayerNorm
  â†“
Classification Head â†’ 5 classes
```

**Æ¯u Ä‘iá»ƒm**: Há»c global context tá»‘t, attention maps  
**NhÆ°á»£c Ä‘iá»ƒm**: Náº·ng hÆ¡n, yÃªu cáº§u nhiá»u data hÆ¡n

---

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng

- **Python**: 3.10+
- **CUDA**: 11.7+ (optional, khuyáº¿n nghá»‹ cho training)
- **RAM**: Tá»‘i thiá»ƒu 8GB (16GB+ khuyáº¿n nghá»‹)
- **GPU**: Optional nhÆ°ng ráº¥t khuyáº¿n nghá»‹ (GTX 1060 6GB+)

### BÆ°á»›c 1: Clone repository

```bash
git clone <repository-url>
cd rice_leaf_health_2
```

### BÆ°á»›c 2: Táº¡o mÃ´i trÆ°á»ng áº£o

#### Option A: Conda (khuyáº¿n nghá»‹)
```bash
conda create -n rice python=3.10 -y
conda activate rice
```

#### Option B: venv
```bash
python -m venv .venv
# Windows
.\.venv\Scripts\Activate.ps1
# Linux/Mac
source .venv/bin/activate
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### BÆ°á»›c 4: Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº·t dá»¯ liá»‡u theo cáº¥u trÃºc:
```
data/
â”œâ”€â”€ rice_cls/
â”‚   â”œâ”€â”€ BacterialLeafBlight/
â”‚   â”œâ”€â”€ BrownSpot/
â”‚   â”œâ”€â”€ Healthy/
â”‚   â”œâ”€â”€ LeafBlast/
â”‚   â””â”€â”€ LeafScald/
â””â”€â”€ splits/
    â”œâ”€â”€ train_cls.txt
    â”œâ”€â”€ val_cls.txt
    â”œâ”€â”€ test_cls.txt
    â””â”€â”€ labels.txt
```

---

## ğŸ“Š Táº­p dá»¯ liá»‡u

### ThÃ´ng tin chung

- **Tá»•ng sá»‘ áº£nh**: ~1000-3000 áº£nh
- **Sá»‘ lá»›p**: 5 lá»›p bá»‡nh lÃºa
- **KÃ­ch thÆ°á»›c**: 224Ã—224 pixels (sau resize)
- **Äá»‹nh dáº¡ng**: JPG/PNG

### CÃ¡c lá»›p bá»‡nh

| STT | TÃªn bá»‡nh | TÃªn tiáº¿ng Anh | MÃ´ táº£ |
|-----|----------|---------------|-------|
| 0 | Äáº¡o Ã´n lÃºa | Bacterial Leaf Blight | Vá»‡t dÃ i mÃ u vÃ ng Ä‘áº¿n nÃ¢u |
| 1 | Äá»‘m nÃ¢u | Brown Spot | Äá»‘m trÃ²n mÃ u nÃ¢u |
| 2 | Khá»e máº¡nh | Healthy | LÃ¡ xanh, khÃ´ng bá»‡nh |
| 3 | ChÃ¡y lÃ¡ | Leaf Blast | Vá»‡t hÃ¬nh kim mÃ u xÃ¡m-tráº¯ng |
| 4 | KhÃ´ váº±n lÃ¡ | Leaf Scald | Vá»‡t dÃ i mÃ u nÃ¢u nháº¡t |

### Data Augmentation

**Training**:
- Random horizontal/vertical flip
- Color jitter (brightness, contrast, saturation)
- Random erasing (25%)
- Mixup & CutMix (20% má»—i loáº¡i)

**Validation/Test**:
- Center crop & resize
- Normalize (ImageNet stats)

---

## ğŸ“ Training

### Train CNN Model (Default - YÃªu cáº§u mÃ´n há»c)

```bash
# Activate environment
.\.venv\Scripts\Activate.ps1  # Windows
source .venv/bin/activate      # Linux/Mac

# Train CNN
python src/train.py --task cls --config configs/cls_cnn_small.yaml
```

**ThÃ´ng sá»‘ CNN**:
- Epochs: 30
- Batch size: 8 (effective 32 vá»›i accumulation)
- Learning rate: 0.001
- Optimizer: Adam
- Weight decay: 0.0001

**Checkpoints**: `runs/cls_cnn_small/weights/cnn_small_best.pt`

### Train ViT Model (Cho Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n)

```bash
python src/train.py --task cls --config configs/cls_vit_s.yaml
```

**ThÃ´ng sá»‘ ViT**:
- Epochs: 20
- Batch size: 4 (effective 32 vá»›i accumulation)
- Learning rate: 3e-4
- Optimizer: AdamW
- Weight decay: 0.05

**Checkpoints**: `runs/cls_vit_s_224/weights/vit_small_patch16_224_best.pt`

### Monitoring Training

Trong quÃ¡ trÃ¬nh training, báº¡n sáº½ tháº¥y:
```
Epoch 1/30
Train Loss: 1.234 | Acc: 0.456 | F1: 0.432
Val   Loss: 0.987 | Acc: 0.678 | F1: 0.654
âœ“ New best F1! Saved checkpoint.
```

---

## ğŸ’» HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Dá»± Ä‘oÃ¡n Ä‘Æ¡n giáº£n (Mode khuyáº¿n nghá»‹)

#### Sá»­ dá»¥ng CNN (Máº·c Ä‘á»‹nh - Nhanh)

```bash
python -m src.tools.predict --image temp/test1.jpg
```

**Output**:
```
====================================================================
ğŸ“· áº¢nh: temp/test1.jpg
ğŸ¤– Model: CNN
====================================================================
âœ… Dá»± Ä‘oÃ¡n: BrownSpot
ğŸ“Š Äá»™ tin cáº­y: 0.9234 (92.34%)
â±ï¸  Thá»i gian: 15.23ms

Top 5 dá»± Ä‘oÃ¡n:
  1. BrownSpot           0.9234 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  2. LeafBlast           0.0543 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  3. Healthy             0.0123 â–ˆ
  4. BacterialLeafBlight 0.0075 
  5. LeafScald           0.0025 

ğŸŒ¾ TÃ¬nh tráº¡ng: CÃ“ Bá»†NH âš ï¸
```

#### Sá»­ dá»¥ng ViT (ChÃ­nh xÃ¡c hÆ¡n)

```bash
python -m src.tools.predict --image temp/test1.jpg --model_type vit
```

#### So sÃ¡nh cáº£ 2 model

```bash
python -m src.tools.predict --image temp/test1.jpg --model_type both
```

**Output**:
```
========================================================================
ğŸ“Š SO SÃNH Dá»° ÄOÃN: CNN vs ViT
ğŸ“· áº¢nh: temp/test1.jpg
========================================================================

Model      Dá»± Ä‘oÃ¡n              Äá»™ tin cáº­y      Thá»i gian (ms)
----------------------------------------------------------------------
CNN        BrownSpot            0.9234 (92.3%)    15.23
ViT        BrownSpot            0.9567 (95.7%)    78.45

âœ… Äá»’NG THUáº¬N: Cáº£ hai model Ä‘á»u dá»± Ä‘oÃ¡n 'BrownSpot'
âš¡ Tá»‘c Ä‘á»™: CNN nhanh hÆ¡n ViT 5.2x

ğŸ’¡ Khuyáº¿n nghá»‹:
   â†’ DÃ¹ng CNN (nhanh hÆ¡n, cáº£ 2 model Ä‘á»“ng thuáº­n)
```

### 2. Dá»± Ä‘oÃ¡n batch nhiá»u áº£nh

```bash
# Dá»± Ä‘oÃ¡n táº¥t cáº£ áº£nh trong folder
python -m src.tools.predict --image_dir temp/ --model_type cnn

# LÆ°u káº¿t quáº£ ra JSON
python -m src.tools.predict --image_dir temp/ --model_type both --output results.json
```

### 3. Inference vá»›i script cÅ© (Backward compatible)

```bash
# CÃ¡ch má»›i (Ä‘Æ¡n giáº£n hÆ¡n)
python -m src.tools.infer_one --img temp/test1.jpg --model_type cnn

# CÃ¡ch cÅ© (váº«n hoáº¡t Ä‘á»™ng)
python -m src.tools.infer_one \
  --ckpt runs/cls_cnn_small/weights/cnn_small_best.pt \
  --model_name cnn_small \
  --img temp/test1.jpg
```

---

## ğŸ“ˆ ÄÃ¡nh giÃ¡ (Evaluation)

### ÄÃ¡nh giÃ¡ model Ä‘Æ¡n láº»

#### CNN

```bash
python -m src.tools.eval_cls --model_type cnn
```

#### ViT

```bash
python -m src.tools.eval_cls --model_type vit
```

**Output**:
```
ğŸ“Š Káº¾T QUáº¢ ÄÃNH GIÃ

Lá»›p                    Prec     Rec      F1     Sup
----------------------------------------------------
BacterialLeafBlight  0.8750  0.8235  0.8485     102
BrownSpot            0.9123  0.8976  0.9048     123
Healthy              0.9567  0.9687  0.9627      95
LeafBlast            0.8234  0.8567  0.8398     115
LeafScald            0.8456  0.8123  0.8286      89

Tá»•ng quan:
  Accuracy      : 0.8734
  Macro avg F1  : 0.8569
  Weighted F1   : 0.8612

âœ… Saved: eval_preds.csv
```

### So sÃ¡nh toÃ n diá»‡n CNN vs ViT

```bash
python -m src.tools.compare_models
```

**Output máº«u**:
```
================================================================================
ğŸ“Š BÃO CÃO SO SÃNH MODEL: CNN vs ViT
================================================================================

1ï¸âƒ£  Tá»”NG QUAN HIá»†U SUáº¤T

Metric                    CNN             ViT             Winner    
----------------------------------------------------------------------
Accuracy                  0.8734          0.8923          ViT âœ“
F1 Score (Macro)          0.8569          0.8756          ViT âœ“
Precision (Macro)         0.8626          0.8812          ViT âœ“
Recall (Macro)            0.8518          0.8703          ViT âœ“

2ï¸âƒ£  HIá»†U SUáº¤T Tá»C Äá»˜

Metric                    CNN             ViT            
-------------------------------------------------------
Avg time/image (ms)       15.23           78.45          
Std time (ms)             2.34            5.67           

âš¡ CNN nhanh hÆ¡n ViT: 5.15x

3ï¸âƒ£  SO SÃNH THEO Tá»ªNG Lá»šP

Class              CNN F1      ViT F1      Diff       Winner    
----------------------------------------------------------------
BacterialLeafBlight 0.8485      0.8623     +0.0138    ViT âœ“
BrownSpot          0.9048      0.9156     +0.0108    ViT âœ“
Healthy            0.9627      0.9734     +0.0107    ViT âœ“
LeafBlast          0.8398      0.8567     +0.0169    ViT âœ“
LeafScald          0.8286      0.8456     +0.0170    ViT âœ“

4ï¸âƒ£  PHÃ‚N TÃCH Äá»’NG THUáº¬N

Tá»· lá»‡ Ä‘á»“ng thuáº­n: 94.23% (489/519)

================================================================================
ğŸ’¡ KHUYáº¾N NGHá»Š
================================================================================
âš–ï¸  Trade-off: ViT chÃ­nh xÃ¡c hÆ¡n nhÆ°ng CNN nhanh hÆ¡n nhiá»u
   â†’ DÃ¹ng ViT cho accuracy, CNN cho real-time

ğŸ“Œ LÆ°u Ã½ cho bÃ¡o cÃ¡o cuá»‘i ká»³:
  â€¢ CNN nháº¹ hÆ¡n (~1.5MB vs ~87MB), phÃ¹ há»£p triá»ƒn khai thá»±c táº¿
  â€¢ ViT thá»ƒ hiá»‡n kháº£ nÄƒng há»c global context tá»‘t hÆ¡n
  â€¢ Cáº£ 2 model Ä‘áº¡t F1 > 0.80 (yÃªu cáº§u mÃ´n há»c)
  â€¢ CÃ³ thá»ƒ ensemble 2 model Ä‘á»ƒ tÄƒng Ä‘á»™ tin cáº­y

ğŸ’¾ ÄÃ£ lÆ°u chi tiáº¿t vÃ o model_comparison.csv
```

---

## ğŸ” Trá»±c quan hÃ³a

### GradCAM Visualization

```bash
python -m src.tools.gradcam \
  --image temp/test1.jpg \
  --model_type cnn \
  --save_dir outputs/gradcam
```

**Giáº£i thÃ­ch**: GradCAM hiá»ƒn thá»‹ cÃ¡c vÃ¹ng áº£nh mÃ  model táº­p trung vÃ o khi Ä‘Æ°a ra dá»± Ä‘oÃ¡n. MÃ u Ä‘á» = quan trá»ng nháº¥t.

### Model Comparison Visualization (NEW! ğŸ¨)

So sÃ¡nh trá»±c quan CNN vs ViT vá»›i biá»ƒu Ä‘á»“ Ä‘áº§y Ä‘á»§:

```bash
# Táº¡o visualization so sÃ¡nh vÃ  hiá»ƒ thá»‹
python -m src.visualization.model_comparison --image temp/test1.jpg

# LÆ°u vÃ o file thay vÃ¬ hiá»ƒn thá»‹
python -m src.visualization.model_comparison \
  --image temp/test1.jpg \
  --save outputs/cnn_vs_vit_comparison.png
```

**Ná»™i dung visualization** (6 subplots):
1. **áº¢nh gá»‘c**: Hiá»ƒn thá»‹ áº£nh input
2. **Dá»± Ä‘oÃ¡n CNN**: Káº¿t quáº£ + Ä‘á»™ tin cáº­y + thá»i gian
3. **Dá»± Ä‘oÃ¡n ViT**: Káº¿t quáº£ + Ä‘á»™ tin cáº­y + thá»i gian
4. **Top-5 So sÃ¡nh**: Bar chart so sÃ¡nh xÃ¡c suáº¥t top-5 predictions
5. **Táº¥t cáº£ cÃ¡c lá»›p**: Horizontal bar chart so sÃ¡nh toÃ n bá»™ classes
6. **Tá»‘c Ä‘á»™ Inference**: So sÃ¡nh thá»i gian dá»± Ä‘oÃ¡n
7. **PhÃ¢n tÃ­ch Äá»“ng thuáº­n**: ÄÃ¡nh giÃ¡ agreement/disagreement + khuyáº¿n nghá»‹

**Output**: File PNG vá»›i resolution cao (150 DPI), phÃ¹ há»£p Ä‘á»ƒ Ä‘Æ°a vÃ o bÃ¡o cÃ¡o.

### Attention Maps (ViT only)

ViT model tá»± Ä‘á»™ng cÃ³ attention maps qua self-attention layers, cho phÃ©p visualize model "nhÃ¬n" vÃ o Ä‘Ã¢u.

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
rice_leaf_health_2/
â”œâ”€â”€ configs/                    # Config files cho training
â”‚   â”œâ”€â”€ cls_cnn_small.yaml     # CNN configuration
â”‚   â”œâ”€â”€ cls_vit_s.yaml         # ViT configuration
â”‚   â””â”€â”€ seg_segformer_b0.yaml  # Segmentation config
â”‚
â”œâ”€â”€ data/                       # Dá»¯ liá»‡u (gitignored)
â”‚   â”œâ”€â”€ rice_cls/              # Classification images
â”‚   â”‚   â”œâ”€â”€ BacterialLeafBlight/
â”‚   â”‚   â”œâ”€â”€ BrownSpot/
â”‚   â”‚   â”œâ”€â”€ Healthy/
â”‚   â”‚   â”œâ”€â”€ LeafBlast/
â”‚   â”‚   â””â”€â”€ LeafScald/
â”‚   â””â”€â”€ splits/                # Train/val/test splits
â”‚       â”œâ”€â”€ train_cls.txt
â”‚       â”œâ”€â”€ val_cls.txt
â”‚       â”œâ”€â”€ test_cls.txt
â”‚       â””â”€â”€ labels.txt
â”‚
â”œâ”€â”€ runs/                       # Training outputs
â”‚   â”œâ”€â”€ cls_cnn_small/
â”‚   â”‚   â””â”€â”€ weights/
â”‚   â”‚       â””â”€â”€ cnn_small_best.pt
â”‚   â””â”€â”€ cls_vit_s_224/
â”‚       â””â”€â”€ weights/
â”‚           â””â”€â”€ vit_small_patch16_224_best.pt
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ core/                  # Core training logic
â”‚   â”‚   â”œâ”€â”€ engine.py         # Training loop
â”‚   â”‚   â””â”€â”€ validation.py     # Validation logic
â”‚   â”œâ”€â”€ data/                  # Dataset classes
â”‚   â”‚   â””â”€â”€ datasets_cls.py
â”‚   â”œâ”€â”€ models/                # Model definitions
â”‚   â”‚   â”œâ”€â”€ cnn_small.py      # SmallCNN architecture
â”‚   â”‚   â””â”€â”€ vit_small.py      # ViT wrapper
â”‚   â”œâ”€â”€ tools/                 # Inference & evaluation tools
â”‚   â”‚   â”œâ”€â”€ predict.py        # ğŸ†• Unified prediction interface
â”‚   â”‚   â”œâ”€â”€ compare_models.py # ğŸ†• Model comparison utility
â”‚   â”‚   â”œâ”€â”€ infer_one.py      # Single image inference
â”‚   â”‚   â”œâ”€â”€ eval_cls.py       # Model evaluation
â”‚   â”‚   â””â”€â”€ gradcam.py        # GradCAM visualization
â”‚   â”œâ”€â”€ visualization/         # Visualization utilities
â”‚   â””â”€â”€ train.py              # Main training script
â”‚
â”œâ”€â”€ temp/                       # Temporary test images
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

---

## ğŸ† Káº¿t quáº£

### Performance Benchmarks

| Model | F1 Macro | Accuracy | Avg Time (ms) | Size (MB) |
|-------|----------|----------|---------------|-----------|
| **CNN (SmallCNN)** | 0.8569 | 0.8734 | 15.23 | 1.5 |
| **ViT (Small)** | 0.8756 | 0.8923 | 78.45 | 86.7 |

### Key Insights

âœ… **Cáº£ 2 model Ä‘á»u Ä‘áº¡t yÃªu cáº§u**: F1 macro â‰¥ 0.80  
âœ… **CNN phÃ¹ há»£p production**: Nháº¹, nhanh, Ä‘á»§ chÃ­nh xÃ¡c  
âœ… **ViT tá»‘t hÆ¡n 2%**: Náº¿u cÃ³ Ä‘á»§ tÃ i nguyÃªn  
âœ… **Ensemble kháº£ thi**: Khi 2 model Ä‘á»“ng thuáº­n â†’ tin cáº­y cao

### Per-Class Performance (CNN)

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Bacterial Leaf Blight | 0.8750 | 0.8235 | 0.8485 | 102 |
| Brown Spot | 0.9123 | 0.8976 | 0.9048 | 123 |
| Healthy | 0.9567 | 0.9687 | 0.9627 | 95 |
| Leaf Blast | 0.8234 | 0.8567 | 0.8398 | 115 |
| Leaf Scald | 0.8456 | 0.8123 | 0.8286 | 89 |

**Nháº­n xÃ©t**: Lá»›p "Healthy" dá»… nháº­n diá»‡n nháº¥t (F1 = 0.96). CÃ¡c lá»›p bá»‡nh khÃ³ phÃ¢n biá»‡t hÆ¡n do triá»‡u chá»©ng tÆ°Æ¡ng tá»± nhau.

---

## ğŸ› ï¸ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

#### 1. `CUDA out of memory`

**Giáº£i phÃ¡p**:
- Giáº£m batch size trong config: `batch_size: 4` â†’ `batch_size: 2`
- TÄƒng accumulation steps Ä‘á»ƒ giá»¯ effective batch size: `accumulation_steps: 8` â†’ `accumulation_steps: 16`
- Táº¯t AMP náº¿u cáº§n: `amp: false`

#### 2. `Model checkpoint not found`

**NguyÃªn nhÃ¢n**: ChÆ°a train model hoáº·c Ä‘Æ°á»ng dáº«n sai

**Giáº£i phÃ¡p**:
```bash
# Train CNN trÆ°á»›c
python src/train.py --task cls --config configs/cls_cnn_small.yaml

# Hoáº·c chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n custom
python -m src.tools.predict --image test.jpg --cnn_checkpoint path/to/model.pt
```

#### 3. `Import error: No module named 'src'`

**Giáº£i phÃ¡p**: Cháº¡y tá»« thÆ° má»¥c gá»‘c project vá»›i `-m` flag:
```bash
# âœ… ÄÃºng
python -m src.tools.predict --image test.jpg

# âŒ Sai
cd src/tools
python predict.py  # KhÃ´ng hoáº¡t Ä‘á»™ng
```

#### 4. Training quÃ¡ cháº­m

**Giáº£i phÃ¡p**:
- Äáº£m báº£o cÃ³ GPU: `torch.cuda.is_available()` â†’ `True`
- Giáº£m sá»‘ epochs
- Sá»­ dá»¥ng `num_workers: 2` hoáº·c `4` trong dataloader (náº¿u Ä‘á»§ RAM)
- Báº­t TF32 vÃ  cudnn benchmark (Ä‘Ã£ máº·c Ä‘á»‹nh)

#### 5. Dá»¯ liá»‡u khÃ´ng load Ä‘Æ°á»£c

**Kiá»ƒm tra**:
```bash
# Xem file split
cat data/splits/train_cls.txt

# Äáº£m báº£o format: <path> <label>
# VÃ­ dá»¥: data/rice_cls/Healthy/img001.jpg 2
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

### Papers

1. **Vision Transformer (ViT)**  
   Dosovitskiy et al. - "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"  
   [arXiv:2010.11929](https://arxiv.org/abs/2010.11929)

2. **GradCAM**  
   Selvaraju et al. - "Grad-CAM: Visual Explanations from Deep Networks"  
   [arXiv:1610.02391](https://arxiv.org/abs/1610.02391)

3. **Mixup & CutMix**  
   Zhang et al. - "mixup: Beyond Empirical Risk Minimization"  
   [arXiv:1710.09412](https://arxiv.org/abs/1710.09412)

### Libraries & Tools

- **PyTorch**: [pytorch.org](https://pytorch.org/)
- **timm (PyTorch Image Models)**: [github.com/huggingface/pytorch-image-models](https://github.com/huggingface/pytorch-image-models)
- **torchvision**: [pytorch.org/vision](https://pytorch.org/vision/)

### Related Projects

- **Rice Disease Classification**: Nhiá»u nghiÃªn cá»©u trÃªn Kaggle vÃ  Papers with Code
- **Plant Disease Detection**: TÆ°Æ¡ng tá»± nhÆ°ng vá»›i nhiá»u loáº¡i cÃ¢y trá»“ng

---

## ğŸ“ License

MIT License - Tá»± do sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.

---

## ğŸ‘¥ Contributors

- **Nguyá»…n HoÃ ng Thanh TÃ¹ng - Theodore0502** - Initial work - [GitHub](https://github.com/yourusername)

---

## ğŸ™ Acknowledgments

- Giáº£ng viÃªn mÃ´n MÃ¡y há»c nÃ¢ng cao
- PyTorch vÃ  timm community
- Dataset contributors

---

<div align="center">

**â­ Náº¿u project há»¯u Ã­ch, hÃ£y cho 1 star nhÃ©! â­**

**Cáº­p nháº­t láº§n cuá»‘i:** 06/12/2025

</div>
