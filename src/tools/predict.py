# src/tools/predict.py
"""
Unified prediction interface supporting both CNN and ViT models.
Default: CNN (for course requirement)
Usage:
    python -m src.tools.predict --image temp/test1.jpg
    python -m src.tools.predict --image temp/test1.jpg --model_type vit
    python -m src.tools.predict --image temp/test1.jpg --model_type both
    python -m src.tools.predict --image_dir temp/ --model_type cnn
"""
import argparse
import os
import time
from pathlib import Path
import torch
from torchvision import transforms
from PIL import Image
import timm
import numpy as np
from src.models.cnn_small import SmallCNN


# C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
DEFAULT_CONFIG = {
    "cnn": {
        "checkpoint": "runs/cls_cnn_small/weights/cnn_small_best.pt",
        "model_name": "cnn_small",
        "img_size": 224,
    },
    "vit": {
        "checkpoint": "runs/cls_vit_s_224/weights/vit_small_patch16_224_best.pt",
        "model_name": "vit_small_patch16_224",
        "img_size": 224,
    }
}


def load_labels(path):
    """Load class labels from file."""
    with open(path, "r", encoding="utf-8") as f:
        return [x.strip() for x in f if x.strip()]


def build_transform(img_size):
    """Build image transformation pipeline."""
    return transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])


def load_model(checkpoint, model_name, num_classes, device):
    """Load trained model from checkpoint."""
    if model_name == "cnn_small":
        model = SmallCNN(num_classes=num_classes)
    else:
        model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)
    
    try:
        sd = torch.load(checkpoint, map_location=device, weights_only=False)
    except TypeError:
        sd = torch.load(checkpoint, map_location=device)
    
    if isinstance(sd, dict) and "model" in sd:
        sd = sd["model"]
    
    model.load_state_dict(sd)
    return model.to(device).eval()


def predict_single(image_path, model, transform, class_names, device, model_type):
    """Predict single image and return results."""
    img = Image.open(image_path).convert("RGB")
    x = transform(img).unsqueeze(0).to(device)
    
    start_time = time.time()
    with torch.no_grad():
        logits = model(x)
        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()
    inference_time = (time.time() - start_time) * 1000  # ms
    
    pred_idx = int(np.argmax(probs))
    pred_name = class_names[pred_idx]
    confidence = float(probs[pred_idx])
    
    return {
        "model_type": model_type,
        "predicted_class": pred_name,
        "predicted_idx": pred_idx,
        "confidence": confidence,
        "inference_time_ms": inference_time,
        "top_predictions": [(class_names[i], float(probs[i])) 
                           for i in np.argsort(-probs)[:min(5, len(class_names))]]
    }


def print_prediction(result, image_path):
    """Print prediction results in a formatted way."""
    print(f"\n{'='*60}")
    print(f"üì∑ ·∫¢nh: {image_path}")
    print(f"ü§ñ Model: {result['model_type'].upper()}")
    print(f"{'='*60}")
    print(f"‚úÖ D·ª± ƒëo√°n: {result['predicted_class']}")
    print(f"üìä ƒê·ªô tin c·∫≠y: {result['confidence']:.4f} ({result['confidence']*100:.2f}%)")
    print(f"‚è±Ô∏è  Th·ªùi gian: {result['inference_time_ms']:.2f}ms")
    print(f"\nTop 5 d·ª± ƒëo√°n:")
    for i, (cls, prob) in enumerate(result['top_predictions'], 1):
        bar = "‚ñà" * int(prob * 30)
        print(f"  {i}. {cls:<20} {prob:.4f} {bar}")
    
    # Ki·ªÉm tra n·∫øu c√≥ l·ªõp "healthy"
    top_class_names = [c.lower() for c, _ in result['top_predictions']]
    if any("healthy" in c for c in top_class_names):
        is_diseased = "healthy" not in result['predicted_class'].lower()
        status = "C√ì B·ªÜNH ‚ö†Ô∏è" if is_diseased else "KH·ªéE M·∫†NH ‚úì"
        print(f"\nüåæ T√¨nh tr·∫°ng: {status}")


def compare_predictions(cnn_result, vit_result, image_path):
    """Compare predictions from both models."""
    print(f"\n{'='*70}")
    print(f"üìä SO S√ÅNH D·ª∞ ƒêO√ÅN: CNN vs ViT")
    print(f"üì∑ ·∫¢nh: {image_path}")
    print(f"{'='*70}")
    
    print(f"\n{'Model':<10} {'D·ª± ƒëo√°n':<20} {'ƒê·ªô tin c·∫≠y':<15} {'Th·ªùi gian (ms)':<15}")
    print("-" * 70)
    print(f"{'CNN':<10} {cnn_result['predicted_class']:<20} "
          f"{cnn_result['confidence']:.4f} ({cnn_result['confidence']*100:.1f}%)    "
          f"{cnn_result['inference_time_ms']:<.2f}")
    print(f"{'ViT':<10} {vit_result['predicted_class']:<20} "
          f"{vit_result['confidence']:.4f} ({vit_result['confidence']*100:.1f}%)    "
          f"{vit_result['inference_time_ms']:<.2f}")
    
    # Ph√¢n t√≠ch
    agree = cnn_result['predicted_class'] == vit_result['predicted_class']
    print(f"\n{'‚úÖ ƒê·ªíNG THU·∫¨N' if agree else '‚ö†Ô∏è B·∫§T ƒê·ªíNG'}: ", end="")
    if agree:
        print(f"C·∫£ hai model ƒë·ªÅu d·ª± ƒëo√°n '{cnn_result['predicted_class']}'")
    else:
        print(f"CNN d·ª± ƒëo√°n '{cnn_result['predicted_class']}', "
              f"ViT d·ª± ƒëo√°n '{vit_result['predicted_class']}'")
    
    # So s√°nh t·ªëc ƒë·ªô
    speedup = vit_result['inference_time_ms'] / cnn_result['inference_time_ms']
    print(f"‚ö° T·ªëc ƒë·ªô: CNN nhanh h∆°n ViT {speedup:.1f}x")
    
    # Khuy·∫øn ngh·ªã
    print(f"\nüí° Khuy·∫øn ngh·ªã:")
    if agree and cnn_result['confidence'] > 0.8:
        print(f"   ‚Üí D√πng CNN (nhanh h∆°n, c·∫£ 2 model ƒë·ªìng thu·∫≠n)")
    elif not agree:
        conf_diff = abs(cnn_result['confidence'] - vit_result['confidence'])
        if conf_diff > 0.2:
            winner = "ViT" if vit_result['confidence'] > cnn_result['confidence'] else "CNN"
            print(f"   ‚Üí N√™n tin {winner} (ƒë·ªô tin c·∫≠y cao h∆°n r√µ r·ªát)")
        else:
            print(f"   ‚Üí N√™n xem x√©t th√™m (2 model kh√¥ng ƒë·ªìng thu·∫≠n v√† ƒë·ªô tin c·∫≠y g·∫ßn b·∫±ng nhau)")
    else:
        print(f"   ‚Üí D√πng ViT n·∫øu c·∫ßn ƒë·ªô ch√≠nh x√°c cao, CNN n·∫øu c·∫ßn t·ªëc ƒë·ªô")


def main():
    parser = argparse.ArgumentParser(
        description="üåæ Rice Leaf Disease Prediction - Dual Model Interface",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # D·ª± ƒëo√°n v·ªõi CNN (m·∫∑c ƒë·ªãnh - y√™u c·∫ßu m√¥n h·ªçc)
  python -m src.tools.predict --image temp/test1.jpg
  
  # D·ª± ƒëo√°n v·ªõi ViT (ƒë·ªô ch√≠nh x√°c cao h∆°n)
  python -m src.tools.predict --image temp/test1.jpg --model_type vit
  
  # So s√°nh c·∫£ 2 model
  python -m src.tools.predict --image temp/test1.jpg --model_type both
  
  # D·ª± ƒëo√°n batch nhi·ªÅu ·∫£nh
  python -m src.tools.predict --image_dir temp/ --model_type cnn
        """
    )
    
    # Input options
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument("--image", type=str, help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ƒë∆°n l·∫ª")
    input_group.add_argument("--image_dir", type=str, help="Th∆∞ m·ª•c ch·ª©a nhi·ªÅu ·∫£nh")
    
    # Model selection
    parser.add_argument(
        "--model_type",
        type=str,
        choices=["cnn", "vit", "both"],
        default="cnn",
        help="Lo·∫°i model: cnn (nhanh, m·∫∑c ƒë·ªãnh), vit (ch√≠nh x√°c), both (so s√°nh)"
    )
    
    # Optional overrides
    parser.add_argument("--cnn_checkpoint", type=str, help="Custom CNN checkpoint path")
    parser.add_argument("--vit_checkpoint", type=str, help="Custom ViT checkpoint path")
    parser.add_argument("--labels_file", type=str, default="data/splits/labels.txt",
                       help="File ch·ª©a t√™n c√°c l·ªõp")
    parser.add_argument("--output", type=str, help="Save results to JSON file")
    
    args = parser.parse_args()
    
    # Setup
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üîß Device: {device}")
    
    class_names = load_labels(args.labels_file)
    num_classes = len(class_names)
    print(f"üìö S·ªë l·ªõp: {num_classes} - {class_names}")
    
    # Load models
    models = {}
    if args.model_type in ["cnn", "both"]:
        cnn_cfg = DEFAULT_CONFIG["cnn"]
        cnn_ckpt = args.cnn_checkpoint or cnn_cfg["checkpoint"]
        if not os.path.exists(cnn_ckpt):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y checkpoint CNN: {cnn_ckpt}")
            print(f"   H√£y train model tr∆∞·ªõc: python src/train.py --task cls --config configs/cls_cnn_small.yaml")
            return
        print(f"üì¶ ƒêang load CNN model t·ª´ {cnn_ckpt}...")
        models["cnn"] = {
            "model": load_model(cnn_ckpt, cnn_cfg["model_name"], num_classes, device),
            "transform": build_transform(cnn_cfg["img_size"]),
            "config": cnn_cfg
        }
    
    if args.model_type in ["vit", "both"]:
        vit_cfg = DEFAULT_CONFIG["vit"]
        vit_ckpt = args.vit_checkpoint or vit_cfg["checkpoint"]
        if not os.path.exists(vit_ckpt):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y checkpoint ViT: {vit_ckpt}")
            print(f"   H√£y train model tr∆∞·ªõc: python src/train.py --task cls --config configs/cls_vit_s.yaml")
            return
        print(f"üì¶ ƒêang load ViT model t·ª´ {vit_ckpt}...")
        models["vit"] = {
            "model": load_model(vit_ckpt, vit_cfg["model_name"], num_classes, device),
            "transform": build_transform(vit_cfg["img_size"]),
            "config": vit_cfg
        }
    
    print(f"‚úÖ ƒê√£ load {len(models)} model(s)\n")
    
    # Get image paths
    if args.image:
        image_paths = [args.image]
    else:
        img_dir = Path(args.image_dir)
        image_paths = list(img_dir.glob("*.jpg")) + list(img_dir.glob("*.png")) + \
                     list(img_dir.glob("*.jpeg"))
        image_paths = [str(p) for p in image_paths]
    
    if not image_paths:
        print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o!")
        return
    
    print(f"üì∏ S·ªë ·∫£nh c·∫ßn d·ª± ƒëo√°n: {len(image_paths)}\n")
    
    # Process images
    all_results = []
    for img_path in image_paths:
        if not os.path.exists(img_path):
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y: {img_path}")
            continue
        
        results = {}
        for model_type, model_data in models.items():
            result = predict_single(
                img_path,
                model_data["model"],
                model_data["transform"],
                class_names,
                device,
                model_type
            )
            results[model_type] = result
        
        # Display results
        if args.model_type == "both":
            compare_predictions(results["cnn"], results["vit"], img_path)
        else:
            print_prediction(results[args.model_type], img_path)
        
        all_results.append({"image": img_path, "predictions": results})
    
    # Save to JSON if requested
    if args.output:
        import json
        with open(args.output, "w", encoding="utf-8") as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {args.output}")


if __name__ == "__main__":
    main()
